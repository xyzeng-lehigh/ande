\subsection{Constants}
\label{sec:bg_cnst}
This manual will use many combinatoric constants, which are listed below:
\begin{itemize}
  \item {\it The Harmonic numbers}.
    \begin{equation}\label{eq:bg_cnst_harm}
      H_n = \sum_{k=1}^n\frac{1}{k} = 1 + \frac{1}{2} + \cdots + \frac{1}{n}\;,
    \end{equation}
    here $n$ is a non-negative integer.
    By convention, we set $H_0=0$.
  \item {\it Binomial coefficient}.
    As usual, $n!$ denotes the factorial of a non-negative integer $n$ and we denote the binomial coefficients:
    \begin{equation}\label{eq:bg_cnst_binom}
      C_n^k = \binom{n}{k} = \frac{n!}{k!(n-k)!}\;,\quad 0\le k\le n\;.
    \end{equation}
  \item {\it Normalized binomial coefficients}.
    A frequently used constantin this manual is normalized binomial coefficients by a certain number:
    \begin{equation}\label{eq:bg_cnst_brat}
      C^{l,r}_k = \frac{C_{l+r}^{l+k}}{C_{l+r}^l} = \frac{l!r!}{(l+k)!(r-k)!}\;,\quad -l\le k\le r\;.
    \end{equation}
    Here $l$ and $r$ are non-negative integers.
\end{itemize}


\subsection{Finite-difference approximations}
\label{sec:bg_fd}
For finite-difference (FD) approximations to a function $u(x)$, we consider nodal values $u_j\approx u(x_j)$, where $x_j=jh$ and $h>0$ is the uniform cell size.

\subsubsection{FD approximation to first-derivative}
\label{sec:bg_fd_dx}
In this section we seek the approximation:
\begin{equation}\label{eq:bg_fd_dx}
  u_x(x_j) \approx \mathcal{D}_xu_j\eqdef \frac{1}{h}\sum_{k=-l}^r\beta_ku_{j+k}
\end{equation}
with optimal accuracy $p=l+r$.
Here we assume $l,r\ge0$, and it is easy to see that $\mathcal{D}_x$ is at least $p$-th order accurate if and only if for any $P(x)\in\mathbb{P}^p$, there is:
\begin{equation}\label{eq:bg_fd_dx_pexact}
  P'(x_j) = \frac{1}{h}\sum_{k=-l}^rP(x_{j+k})\;,
\end{equation}
which is known as the $p$-exactness condition.
One can show that given the stencil $(l,r)$, the operator $\mathcal{D}_x$ with order $p=l+r$ is unique and optimal, which is denoted $\mathcal{D}_x^{l,r}$.

\medskip

\noindent
\textbf{\textit{Explicit formula of coefficients}}.

\smallskip
The first consequence of~\cref{eq:bg_fd_dx_pexact} is the explicit formula for $\mathcal{D}^{l,r}_x$, as derived next.
Define $L(x)=\prod_{k=-l}^r(x-x_{j+k})\in\mathbb{P}^{p+1}$ and $L_k(x)=L(x)/(x-x_{j+k})\in\mathbb{P}^p$, then the Lagrangian interpolation basis polynomials for the set $\{x_{j+k}:\,-l\le k\le r\}$ are given by $\{\hat{L}_k(x)\eqdef L_k(x)/L_k(x_{j+k}):\,-l\le k\le r\}$.
It follows that for all $P(x)\in\mathbb{P}^p$:
\begin{displaymath}
  P(x) = \sum_{k=-l}^rP(x_{j+k})\hat{L}_k(x)\;,
\end{displaymath}
hence the coefficients in $\mathcal{D}^{l,r}_xu_j=\frac{1}{h}\sum_{k=-l}^r\beta_k^{l,r}u_{j+k}$ is given by:
\begin{equation}\label{eq:bg_fd_dx_coef}
  \beta_k^{l,r} = h\hat{L}_k'(x_j) = \left\{\begin{array}{lcl}
    \frac{(-1)^{k-1}}{k}C_k^{l,r}\,, & & -l\le k\le r,\,k\ne0 \\ \vspace{-.1in} \\
    H_l-H_r\,, & & k=0\;.
  \end{array}\right.
\end{equation}
%Here $H_m=1+\frac{1}{2}+\cdots+\frac{1}{m}$ are Harmonic numbers and by convention we denote $H_0=0$.
When the stencil is obvious from the context, we shall write $\mathcal{D}_x^{l,r}$ and $\beta^{l,r}_k$ as $\mathcal{D}_x$ and $\beta_k$ for short.

\medskip

\noindent
\textbf{\textit{Semi-discretized approximation to linear advection equations}}.

\smallskip
Let us consider the semi-discretization of the linear advection equation $u_t+cu_x=0$, where $c>0$ is a constant.
Following the standard Fourier analysis, we consider a simple wave given by $u(x,t)=e^{i\kappa(x-ct)}$.
The semi-discretized scheme is given by:
\begin{equation}\label{eq:bg_fd_dx_adv_semi}
  u_j' = -c\mathcal{D}_xu_j\;.
\end{equation}
On the one hand, the local truncation error to this method is $p$-th order, that is if one substitute $u_j$ with the exact solution, they obtain:
\begin{displaymath}
  -ic\kappa e^{i\kappa(x_j-ct)} = u_t(x_j,t) = -cu_x(x_j,t) = -\frac{c}{h}\sum_{k=-l}^r\beta_ku(x_{j+k},t) + O(h^p) = -\frac{c}{h}\sum_{k=-l}^r\beta_k e^{i\kappa(x_{j+k}-ct)} + O(h^p)\;,
\end{displaymath}
which can be simplified to:
\begin{equation}\label{eq:bg_fd_dx_adv_lte}
  i\theta = \sum_{k=-l}^r\beta_ke^{ik\theta}+O(\theta^{p+1})\quad\textrm{or}\quad
  -i\theta e^{-ir\theta} = -\sum_{k=-l}^r\beta_ke^{-i(r-k)\theta} + O(\theta^{p+1})\;,
\end{equation}
where $\theta=\kappa h$.
The accuracy concerns $\theta\approx0$, or $e^{-i\theta}\approx1$; to this end we may define $e^{-i\theta}=1+z$, so that $O(\theta)=O(z)$ and~\cref{eq:bg_fd_dx_adv_lte}$_2$ reads:
\begin{displaymath}
  S_r(z) = (1+z)^r\ln(1+z) = S_{l,r}(z) + R_{l,r}(z)\;,\ S_{l,r}(z) = -\sum_{k=-l}^r\beta_k(1+z)^{r-k}\in\mathbb{P}^p(z),\ R_{l,r}(z)=O(z^{p+1})\;.
\end{displaymath}
It follows that $S_{l,r}(z)$ is the leading $p$-th degree polynomial approximation in the Taylor series of $S_r(z)=(1+z)^r\ln(1+z)$ about $z=0$, and the remainder term $R_{l,r}(z)$ can be obtained by the Taylor theorem in integral form:
\begin{equation}\label{eq:bg_fd_dx_adv_rem}
  R_{l,r}(z) = \int_0^1\frac{(1-t)^pS_r^{(p+1)}(tz)z^{p+1}}{p!}dt\;.
\end{equation}
By direct calculation:
\begin{displaymath}
  S_r^{(p+1)}(z) = \frac{(-1)^{p-r}r!(p-r)!}{(1+z)^{p+1-r}} = \frac{(-1)^lr!l!}{(1+z)^{l+1}}\;.
\end{displaymath}
This gives rise to the following identity:
\begin{displaymath}
  i\theta = -\sum_{k=-l}^r\beta_ke^{-ik\theta}+e^{-ir\theta}\int_0^1\frac{(-1)^l(1-t)^pr!l!z^{p+1}}{p!(1+tz)^{l+1}}dt\;.
\end{displaymath}
In the last integral, the integration path is the straight line from $1$ to $1+z=e^{i\theta}$; and the integrant has a singularity along the path if $z=-1$.
Hence by the Cauchy's integral theorem, for all $0\le\theta<\pi$ we may pick a different path connecting $1$ and $e^{i\theta}$, namely $e^{i\varphi}, 0\le\varphi\le\theta$, and obtain:
\begin{align}
  \notag
  i\theta &= -\sum_{k=-l}^r\beta_ke^{-ik\theta}+e^{-ir\theta}\int_0^{\theta}\frac{(-1)^l(e^{i\theta}-e^{i\varphi})^pr!l!}{p!e^{i(l+1)\varphi}}de^{i\varphi}\;. \\
  \notag
  &= -\sum_{k=-l}^r\beta_ke^{-ik\theta}+\frac{(-1)^lr!l!}{p!}\int_0^{\theta}(e^{i(\theta-\varphi)}-1)^pe^{-ir(\theta-\varphi)}d\varphi \\
  \label{eq:bg_fd_dx_adv_semi_symbol}
  &= -\sum_{k=-l}^r\beta_ke^{-ik\theta}+\frac{(-1)^lr!l!}{p!}\int_0^{\theta}(2i\sin\frac{\varphi}{2})^pe^{\frac{1}{2}(l-r)i\varphi}d\varphi\;.
\end{align}
To study the stability of the semi-discretized system~\cref{eq:bg_fd_dx_adv_semi}, we assume initial data $u(x,0)=e^{i\kappa x}$ then the solution is given by $u_j(t)=A(t)e^{ij\theta}$, where:
\begin{displaymath}
  \frac{A'(t)}{A(t)} = -\frac{c}{h}\sum_{k=-l}^r\beta_ke^{ik\theta} = -\frac{c}{h}\mu(\theta) = -i\frac{c}{h}\omega(\theta)\;.
\end{displaymath}
Here $\omega$ is the numerical wave number and $\omega(\theta)=\theta+O(\theta^{p+1})$ by~\cref{eq:bg_fd_dx_adv_lte}; and stability of the semi-discretized method requires $\oname{Re}\mu(\theta)\ge 0$ for all $0\le \theta\le 2\pi$, and any zero of $\oname{Re}\mu(\theta)$ is simple:
\begin{equation}\label{eq:bg_fd_dx_adv_re}
  \oname{Re}\mu = \sum_{k=-l}^r\beta_k\cos(k\theta)
\end{equation}

Lastly, we describe the stability region and order stars of the semi-discretized methods.
By~\cref{eq:bg_fd_dx_adv_lte}, we have
\begin{equation}\label{eq:bg_fd_dx_mu_order}
  \sigma(\theta) = \mu(\theta) - i\theta = O(\theta^{p+1})\;;
\end{equation}
and for stability, one requires $\oname{Re}\mu\ge0$ or $\oname{Re}\sigma\ge0$ for all $0\le\theta\le2\pi$, and any zero of $\oname{Re}\sigma$ is simple.
Denoting $z=i\theta$ and abusing the notation $\mu(z)$ and $\sigma(z)=\mu(z)-z$, one defines the stability region of the semi-discretized method:
\begin{equation}\label{eq:bg_fd_dx_mu_stab}
  \mathcal{S} = \{z\in\mathbb{C}:\,\oname{Re}\sigma(z)\ge0\}\;,
\end{equation}
then a necessary condition (and almost sufficient condition less the simple-root requirement on the imaginary axis) for the method to be stable is $i\mathbb{R}\subseteq\mathcal{S}$.
The order star is defined as the complement of $\mathcal{S}$:
\begin{equation}\label{eq:bg_fd_dx_mu_os}
  \mathcal{O} = \{z\in\mathbb{C}:\,\oname{Re}\sigma(z)<0\}\;.
\end{equation}
In the plots we will make for the order stars, the regions of $\mathcal{O}$ are indicated by shaded regions and those in the interior of $\mathcal{S}$ are not colored.
In the vicinity of $z=0$, $\sigma(z)=O(z^{p+1})$; thus $z=0$ is adjoined by $p+1$ sectors of $\mathcal{O}$, interlaced by $p+1$ sectors of $\mathcal{S}$, and each sector has the asymptotic angle $\frac{\pi}{p+1}$ as $z\to0$.
This is also the origin of the name ``order star''.

\subsection{Finite-volume approximations}
\label{sec:bg_fv}
Finite-volume approximation is not too much from the finite-difference ones, except that they are usually in conservative forms.

\subsection{Hybrid-variable approximations}
\label{sec:bg_hv}
For hybrid-variable (HV) approximations to a function $u(x)$, we consider both nodal values $u_j\approx u(x_j)$ and cell-averaged values $\overline{u}_{\phf{j}}=\frac{1}{h}\int_{x_j}^{x_{j+1}}u(x)dx$.

\subsubsection{HV approximation to first-derivative}
\label{sec:bg_hv_dx}
To approximate $u_x(x_j)$, we consider the following general discrete operator:
\begin{equation}\label{eq:bg_hv_dx}
  u_x(x_j) \approx [\mathcal{D}_xu]_j \eqdef \frac{1}{h}\sum_{k=-\bl}^{\br-1}\alpha_k\overline{u}_{\phf{j+k}}+\frac{1}{h}\sum_{k=-l}^r\beta_ku_{j+k}\;.
\end{equation}
We shall only consider a contiguous stencil, meaning $\max(0,\bl-1)\le l\le \bl$ and $\max(0,\br-1)\le r\le\br$.
The optimal order of accuracy of~\cref{eq:bg_hv_dx} is $p=l+r+\bl+\br$, and the $p$-exactness condition is for any $P(x)\in\mathbb{P}^p$:
\begin{equation}\label{eq:bg_hv_dx_pexact}
  P'(x_j) = \frac{1}{h}\sum_{k=-\bl}^{\br-1}\alpha_k\frac{1}{h}\int_{x_{j+k}}^{x_{j+k+1}}P(x)dx+\frac{1}{h}\sum_{k=-l}^r\beta_kP(x_{j+k})\;.
\end{equation}
Again, we denote this unique operator by $[\mathcal{D}^{\bl,\br,l,r}_x]$, or $[\mathcal{D}_x]$ for short when there is no ambiguity.

\medskip

\noindent
\textbf{\textit{Explicit formula of coefficients}}.

\smallskip
Similar as before, the $p$-exactness condition allows one to compute the coefficients $\alpha_k$ and $\beta_k$ explicitly.
The idea is to consider the anti-derivative of $P$, which is a polynomial of degree no more than $p+1$.
And~\cref{eq:bg_hv_dx_pexact} can be rephrased as for all $Q\in\mathbb{P}^{p+1}$:
\begin{align}
  \notag
  Q''(x_j) &= \frac{1}{h}\sum_{k=-\bl}^{\br-1}\alpha_k\frac{1}{h}\left[Q(x_{j+k+1})-Q(x_{j+k})\right]+\frac{1}{h}\sum_{k=-l}^r\beta_kQ'(x_{j+k}) \\
  \label{eq:bg_hv_dx_qexact}
  &= \sum_{k=-\bl}^{\br}\frac{\Delta\alpha_k}{h^2}Q(x_{j+k}) + \sum_{k=-l}^{r}\frac{\beta_k}{h}Q'(x_{j+k})\;,
\end{align}
where $\Delta\alpha_k=\alpha_{k-1}-\alpha_k$, $-\bl\le k\le\br$ and we assume $\alpha_{-\bl-1}=\alpha_{\br}=0$.
Thus the coefficients $\Delta\alpha_k$ and $\beta_k$ are derived using the Hermite interpolation polynomials, at least when $\bl=l$ and $\br=r$ (in other cases, some adjustments need to be made).

In the end, the coefficients are computed as below:
\begin{subequations}\label{eq:bg_hv_dx_coef}
  \begin{align}
    \label{eq:bg_hv_dx_coef_alpha_neg}
    \alpha_{\nu} &= -(1-\delta_{\bl l})\frac{2}{\bl^2}C^{\bl,\br}_{-\bl}C^{\bl,r}_{-\bl}-\sum_{k=-l}^{\nu}\frac{2(1+k(H_{\bl+k}-H_{\br-k}+H_{l+k}-H_{r-k}))}{k^2}C^{\bl,\br}_kC^{l,r}_k\,,\ -\bl\le\nu<0 \\
    \label{eq:bg_hv_dx_coef_alpha_pos}
    \alpha_{\nu} &= \sum_{k=\nu+1}^{r}\frac{2(1+k(H_{\bl+k}-H_{\br-k}+H_{l+k}-H_{r-k}))}{k^2}C^{\bl,\br}_kC^{l,r}_k+(1-\delta_{\br r})\frac{2}{\br^2}C^{\bl,\br}_{\br}C^{l,\br}_{\br}\,,\ 0\le\nu<\br \\
    \label{eq:bg_hv_dx_coef_beta_zero}
    \beta_0 &= 2(H_{\bl}-H_{\br}+H_l-H_r) \\
    \label{eq:bg_hv_dx_coef_beta_nzero}
    \beta_{\nu} &= -\frac{2}{\nu}C^{\bl,\br}_{\nu}C^{l,r}_{\nu}\,,\ -l\le\nu\le r\,,\ \nu\ne0\;.
  \end{align}
\end{subequations}

\medskip

\noindent
\textbf{\textit{Semi-discretized approximation to linear advection equations}}.

\smallskip
Consider the semi-discretization of $u_t+cu_x=0$ with ($c>0$) again, let the initial condition be given by a simple wave $u(x,t)=e^{i\kappa(x-ct)}$, one has:
\begin{displaymath}
  u_j' = -c[\mathcal{D}_xu]_j\;.
\end{displaymath}
Substituting the exact solution, there is:
\begin{displaymath}
  -ic\kappa e^{i\kappa(x_j-ct)} = u_t(x_j,t) = -cu_x(x_j,t) = -\frac{c}{h}\left[\sum_{k=-\bl}^{\br-1}\frac{\alpha_k}{h}\int_{x_{j+k}}^{x_{j+k+1}}e^{i\kappa(x-ct)}dx+\sum_{k=-l}^r\beta_ke^{i\kappa(x_{j+k}-ct)}\right]+O(h^p)
\end{displaymath}
or equivalently:
\begin{equation}\label{eq:bg_hv_dx_adv_lte}
  i\theta = \sum_{k=-\bl}^{\br-1}\frac{\alpha_k(e^{i(k+1)\theta}-e^{ik\theta)})}{i\theta}+\sum_{k=-l}^r\beta_ke^{ik\theta}+O(\theta^{p+1})
  = \frac{1}{i\theta}(e^{i\theta}-1)\alpha(e^{i\theta})+\beta(e^{i\theta})+O(\theta^{p+1})\;,
\end{equation}
here $\alpha(\cdot)$ and $\beta(\cdot)$ are Laurent polynomials:
\begin{equation}\label{eq:bg_hv_dx_adv_poly}
  \alpha(z)=\sum_{k=-\bl}^{\br-1}\alpha_kz^k\;,\quad\beta(z)=\sum_{k=-l}^r\beta_kz^k\;.
\end{equation}
Stability analysis of the semi-discretized method:
\begin{equation}\label{eq:bg_hv_dx_adv_semi}
  \left\{\begin{array}{l}
    \overline{u}'_{\phf{j}} = -\frac{c}{h}\left(u_{j+1}-u_j\right)\;, \\ \vspace*{-.1in} \\
    u'_j = -\frac{c}{h}[\mathcal{D}_xu]_j
  \end{array}\right.
\end{equation}
gives rise to the following characteristic equation:
\begin{equation}\label{eq:bg_hv_dx_adv_semi_char}
  \mu^2-\beta(e^{i\theta})\mu-(e^{i\theta}-1)\alpha(e^{i\theta}) = 0\;.
\end{equation}
It has two roots $\mu_1=i\theta+O(\theta^{p+2})$ and $\mu_2=\beta(0)+O(\theta)$; thus stability of the method requires $\max\oname{Re}\mu_{1,2}(\theta)\ge0$ and zeroes are simple.
One can show that this is equivalent to show:
\begin{equation}\label{eq:bg_hv_dx_adv_semi_iff}
  \oname{Re}\beta(\theta)\ge0\;,\quad\oname{Re}\beta\oname{Re}\left[\overline{H}(e^{i\theta}-1)G\right]+\left\{\oname{Im}\left[(e^{i\theta}-1)G\right]\right\}^2\le0\;.
\end{equation}

Alternatively, one can define the stability region and order stars, with the aid of the language of Riemann surfaces.
To this end, \cref{eq:bg_hv_dx_adv_poly} defines a Riemann surface:
\begin{equation}\label{eq:bg_hv_dx_adv_rs}
  \mathbb{M} = \{\bs{z}=(z,\mu)\in\mathbb{S}\times\mathbb{C}:\,\mu^2-\beta(e^z)\mu-(e^z-1)\alpha(e^z)=0\}\;,
\end{equation}
where $\mathbb{S}$ is the strip $\{z\in\mathbb{C}:\,-\pi\le\oname{Im}z\le\pi\}$ with the two edges identified with each other.
We define the projections:
\begin{equation}\label{eq:bg_hv_dx_adv_proj}
  \rho\,:\,\mathbb{M}\rightarrow\mathbb{S}\;,\ \rho(\bs{z})=z\;;\quad
  E\,:\,\mathbb{M}\rightarrow\mathbb{C}\;,\ E(\bs{z})=\mu\;.
\end{equation}
Then the stability region $\mathcal{S}$ and the order star $\mathcal{O}$ are defined respectively as:
\begin{align}
  \label{eq:bg_hv_dx_adv_stab}
  \mathcal{S} &= \{\bs{z}\in\mathbb{M}:\,\oname{Re}\sigma(\bs{z})>0\}\;, \\
  \label{eq:bg_hv_dx_adv_os}
  \mathcal{O} &= \{\bs{z}\in\mathbb{M}:\,\oname{Re}\sigma(\bs{z})<0\}\;,
\end{align}
where $\sigma(\bs{z}) = E(\bs{z}) - \rho(\bs{z})$.
The method is stable if $\rho^{-1}([-i\pi,\,i\pi])$ is contained in $\mathcal{S}$ except for the origin $\bs{z}=(0,0)$.

{\bf Remark}: The above discussion is not entirely correct, as it omits the discussion of branching point, which forms a set of isolated points in $\mathbb{M}$, which we denote by $\mathcal{B}$:
\begin{equation}\label{eq:bg_hv_dx_adv_br}
  \mathcal{B} = \{\bs{z}=(z,\mu)\in\mathbb{M}:\,\mu \textrm{ is a double root of } \mu^2-\beta(e^z)\mu-(e^z-1)\alpha(e^z)=0\}\;.
\end{equation}
